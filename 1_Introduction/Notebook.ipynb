{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**This exercise starts by taking an overview of the last exercise done in the begginer level repo.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from constants import *\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the data. In this case, train.csv is for training, test.csv is for testing.\n",
    "read_csv function allows us to choose the column that's going to be used as index. In this case, 'Id' column, which, by the way, is the first one, is arguably the best choice, as it contains the row number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(PATH_TRAIN_CSV, index_col = 'Id')\n",
    "test_data  = pd.read_csv(PATH_TEST_CSV, index_col = 'Id')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtain target ('y') and features/predictors ('X')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = train_data['SalePrice']\n",
    "# y_test = test_data['SalePrice']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we print the test data columns, we will find no sale price series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(test_data.columns)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trivia fact: 'y' variable could have been declared as y = train_data.SalePrice as well. However, declaring it as it's done above is strongly recommended, because it covers a more general case. If the variable name has special characters within it, then the dot ('.') method, it's to say, accessing the variable as a member of a class will no longer be possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['LotArea', 'YearBuilt', '1stFlrSF', '2ndFlrSF', 'FullBath', 'BedroomAbvGr', 'TotRmsAbvGrd']\n",
    "X = train_data[features]\n",
    "X_test = test_data[features]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Until this point, y and X variables have been recorded for the train and test cases. Note that testing is not considered to be the same as validation.\n",
    "\n",
    "In fact, the next line is going to break y and X variables into training and validation (not testing) data chunks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, train_size = SIZE_TRAIN, test_size = SIZE_VAL, random_state = SPLIT_RANDOM_STATE)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some models are going to be defined now, all of them based in the RFR structure.\n",
    "\n",
    "Some notes about the passed arguments:\n",
    "- n_estimators is the number of decision trees that each forest is going to use.\n",
    "- criterion is the way the quality of each split in each tree is measured. In this case, minimizing the MAE is wanted, getting the median of each terminal node.\n",
    "- max_depth indicates which the maximum depth of each tree should be."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1 = RandomForestRegressor(n_estimators = 50,                                                                  random_state = RFR_RANDOM_STATE)\n",
    "model_2 = RandomForestRegressor(n_estimators = 100,                                                                 random_state = RFR_RANDOM_STATE)\n",
    "model_3 = RandomForestRegressor(n_estimators = 100, criterion ='absolute_error',                                    random_state = RFR_RANDOM_STATE)\n",
    "model_4 = RandomForestRegressor(n_estimators = 200,                                 min_samples_split = 20,         random_state = RFR_RANDOM_STATE)\n",
    "model_5 = RandomForestRegressor(n_estimators = 100, max_depth = 7,                                                  random_state = RFR_RANDOM_STATE)\n",
    "\n",
    "models = {\n",
    "    model_1 : -1,\n",
    "    model_2 : -1,\n",
    "    model_3 : -1,\n",
    "    model_4 : -1,\n",
    "    model_5 : -1\n",
    "    }"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, a function that gets a model and determines its mean absolute error is defined.\n",
    "\n",
    "Trivia fact: python allows the developer to set some defafult variables, by using var = default_value kind of statement when declaring the input parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_model(model, X_t = X_train, X_v = X_valid, y_t = y_train, y_v = y_valid):\n",
    "    model.fit(X_t, y_t)\n",
    "    prediction = model.predict(X_v)\n",
    "    return mean_absolute_error(y_v, prediction)\n",
    "\n",
    "for i in models.keys():\n",
    "    MAE = score_model(i)\n",
    "    print(\"Model: %d\\t MAE %d\" % (list(models.keys()).index(i) + 1, MAE))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As seen, the third model seems to be the most effective one. Thus, it is going to be stored in a variable. Note that the method that generates the random forest is called again, because the current third model is already fitted, and it's consequently biased."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = RandomForestRegressor(n_estimators = 100, criterion ='absolute_error', random_state = RFR_RANDOM_STATE)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Same as in the previous exercises (done in the begginer tutorial series), the whole data set (not only the train side) is used to fit the model again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model.fit(X, y)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, the model should be tested against the test data set (not the validation data set)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_test_data = best_model.predict(X_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Store the prediction in a Dataframe class object. Then, it's going to be stored in an output CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_test_data_DF = pd.DataFrame({'Id': X_test.index, 'SalePrice': predictions_test_data})\n",
    "predictions_test_data_DF.to_csv(PATH_SUBMISSION, index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
